{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7be856b9-7903-5cf3-19b3-fce7ece95502"
   },
   "source": [
    "SMOTE with Imbalance Data using imblearn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "21256b6b-21dd-5dbb-7e8a-43af8b852cdd"
   },
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "6b44dc91-42aa-a99a-d4ff-e9e2f8002bdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\gurun\\Desktop\\VAC Predictive Analysis Python\\Module 2 More into Python\\\\1 Handling Data Imbalance\\creditcard.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the count or frequency of Fraud and Non-Fraud classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ece4502d-7ac4-adcc-8a44-0c33a92f5e44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(data['Class']).plot.bar()\n",
    "plt.title('Fraud class histogram')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f66f8804-2605-d915-cb7a-d6f1b0afcf13"
   },
   "source": [
    "### We can infer that there is an imbalance in the data because the no. of Fraud cases are way much lesser then no. of Non-Fraud Cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also, looking at the dataframe, the values Amount column are scaling equally with the values of other columns. And Time column may not be necessary. So we do Feature Scaling of Amount column.\n",
    "\n",
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "12741d1e-6168-ca3b-71ea-bffc3541dece"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time', 'Amount'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the code imports the StandardScaler class from the sklearn.preprocessing module. This class is a transformer that scales and standardizes features by removing the mean and scaling to unit variance.\n",
    "\n",
    "Next, a new column called normAmount is created in the data dataframe by fitting and transforming the Amount column using the StandardScaler object. The reshape(-1, 1) method is used to convert the 1-dimensional array of Amount values into a 2-dimensional array, which is the expected format for StandardScaler.\n",
    "\n",
    "Finally, the Time and Amount columns are dropped from the data dataframe using the drop() method with the axis=1 argument, which specifies that columns should be dropped rather than rows.\n",
    "\n",
    "The resulting data dataframe has the same number of rows as the original, but with two fewer columns (Time and Amount) and one new column (normAmount). This is a common preprocessing step to prepare the data for machine learning models, as it removes unnecessary or irrelevant features and scales the remaining features to a similar range to avoid issues with varying units and magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Feature Scaling, now we split the data into Independent Variables (x) and Dependent Variables (y). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "ada96df8-6788-87df-6ffc-2fe29ad94521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 29)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.iloc[:, data.columns != 'Class']) #Independent Variables\n",
    "y = np.array(data.iloc[:, data.columns == 'Class']) #Dependent Variables\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using imblearn library, we will handle the data imbalance by over-sampling the minority class (Fraud Cases) using SMOTE. \n",
    "### There is ADASYN as well using which we can do the over-sampling of minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\gurun\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from imbalanced-learn->imblearn) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\gurun\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\gurun\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gurun\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Installing collected packages: joblib, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0 joblib-1.2.0\n"
     ]
    }
   ],
   "source": [
    "#Installing necessary library\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE for Over-sampling of minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we split the data into Train-set and Test-set using train_test_split funtcion from sklearn.model_selection library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "7676067e-cd33-37e7-fcd6-f7112eba414c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (199364, 29)\n",
      "Number transactions y_train dataset:  (199364, 1)\n",
      "Number transactions X_test dataset:  (85443, 29)\n",
      "Number transactions y_test dataset:  (85443, 1)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Over-sampling of minority class is done using fit_resample() method of an instance of SMOTE class. It is performed only in Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "fd8a5374-412b-0175-e18e-aac83de1ef08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': [345]\n",
      "Before OverSampling, counts of label '0': [199019] \n",
      "\n",
      "After OverSampling, the shape of train_X: (398038, 29)\n",
      "After OverSampling, the shape of train_y: (398038,) \n",
      "\n",
      "After OverSampling, counts of label '1': 199019\n",
      "After OverSampling, counts of label '0': 199019\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet provided involves using the SMOTE (Synthetic Minority Over-sampling Technique) algorithm for performing oversampling of the minority class in a binary classification problem.\n",
    "\n",
    "SMOTE is a widely-used technique for dealing with imbalanced datasets, where the number of instances in one class is significantly smaller than the other. It works by generating synthetic samples from the minority class, which are similar to the existing instances, and adding them to the training set.\n",
    "\n",
    "In the code, the SMOTE function is initialized with a random_state value of 2. This parameter is used to ensure that the results obtained are reproducible, i.e., running the same code with the same random_state value will produce the same output.\n",
    "\n",
    "The fit_resample method is then used to perform oversampling on the training data (X_train and y_train), where X_train is the feature matrix and y_train is the corresponding target labels. The ravel() method is used to convert the y_train array into a 1D array.\n",
    "\n",
    "The fit_resample method returns the oversampled feature matrix and target labels, which are assigned to X_train_res and y_train_res, respectively. These oversampled datasets can then be used for training a classifier to improve the model's performance on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "593d69fa-b8fe-3451-96aa-ebc920e97ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=3,\n",
       "             param_grid={'C': array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "\n",
    "parameters = {\n",
    "    'C': np.linspace(1, 10, 10)\n",
    "             }\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters, cv=5, verbose=5, n_jobs=3)\n",
    "clf.fit(X_train_res, y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a detailed explanation of each line of the code snippet you provided, along with simple examples to illustrate the concepts:\n",
    "\n",
    "`from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report`\n",
    "\n",
    "The first line imports the GridSearchCV class from the model_selection module of scikit-learn library. The second line imports the LogisticRegression class from the linear_model module. The third line imports several metrics that will be used to evaluate the performance of the model later.\n",
    "\n",
    "`parameters = {\n",
    "    'C': np.linspace(1, 10, 10)\n",
    "             }`\n",
    "             \n",
    "This line creates a dictionary that contains a range of values for the regularization parameter C of the logistic regression model. The linspace() method from numpy generates a sequence of 10 numbers between 1 and 10 (inclusive) that are evenly spaced. In this example, the values for C will range from 1 to 10 with equal increments.\n",
    "\n",
    "`lr = LogisticRegression()`\n",
    "\n",
    "This line creates an instance of the logistic regression model. By default, it uses l2 regularization with a regularization strength of 1.0.\n",
    "\n",
    "`clf = GridSearchCV(lr, parameters, cv=5, verbose=5, n_jobs=3)`\n",
    "\n",
    "This line creates an instance of the GridSearchCV class with the following parameters:\n",
    "\n",
    "lr: The logistic regression model instance we created earlier.\n",
    "parameters: The dictionary containing the parameter grid that will be used for hyperparameter tuning.\n",
    "cv=5: The number of folds to use for cross-validation during the hyperparameter tuning process. In this case, we are using 5-fold cross-validation.\n",
    "verbose=5: The verbosity level of the output during the hyperparameter tuning process. In this case, we will get detailed output at every iteration of the grid search.\n",
    "n_jobs=3: The number of CPU cores to use for parallelization. In this case, we are using 3 cores.\n",
    "\n",
    "`clf.fit(X_train_res, y_train_res.ravel())`\n",
    "\n",
    "This line fits the GridSearchCV object to the training data. The fit() method performs the hyperparameter tuning by running cross-validation on all combinations of the parameters in the grid. The oversampled training data (X_train_res and y_train_res.ravel()) are used for this process.\n",
    "\n",
    "The best hyperparameters are selected based on the chosen scoring metric (which defaults to accuracy for classification tasks). Once the hyperparameters are selected, a new logistic regression model is trained using the best parameters on the entire training set, including both the original and oversampled data.\n",
    "\n",
    "The best hyperparameters can be accessed using the best_params_ attribute of the GridSearchCV object, like so: clf.best_params_.\n",
    "\n",
    "Once the hyperparameters are obtained, they can be used to train a final logistic regression model on the original training data (without oversampling), and the model's performance can be evaluated using the test set. The metrics imported from scikit-learn, such as confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, and classification_report, can be used to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "de1dc6a4-78ab-7699-d9f1-cd0c2bf0920c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 9.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 440,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
